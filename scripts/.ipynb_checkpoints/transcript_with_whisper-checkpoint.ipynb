{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4752c217-ba79-407a-809a-377daaa3664f",
   "metadata": {},
   "source": [
    "# Retranscrire ses entretiens avec Whisper\n",
    "\n",
    "[Whisper](https://github.com/openai/whisper) est le nom donné par Open IA (Chat GPT) à son système de reconnaissance vocale multilingue. Dans ce tutoriel, nous montrons deux façon d'utiliser Whisper:\n",
    "\n",
    "1. Une utilisation de Whisper en \"local\"\n",
    "2. Via les services Huma-Num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eab461",
   "metadata": {},
   "source": [
    "## Whisper en local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91906f6",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous voyons comment utiliser Whisper -- l'outil de retranscription audio proposé par Open-ai -- en \"local\" à l'aide d'un script Python. C'est-à-dire qu'on installe whisper et le modèle sur sa machine.\n",
    "\n",
    "Du fait de la popularité de Whisper, de nombreux tutoriaux qui fleurissent :\n",
    "\n",
    "- https://www.css.cnrs.fr/whisper-pour-retranscrire-des-entretiens/\n",
    "- https://analyzingalpha.com/openai-whisper-python-tutorial\n",
    "\n",
    "###  Quel est l'intérêt ?\n",
    "\n",
    "1. on maîtrise la \"destinée\" de ses données : elles restent privées. Il existe toutefois des applications web qui promettent aussi de protéger vos données comme [Whisper Web](https://whisper-web.pascal-mietlicki.fr/).\n",
    "\n",
    "2. on apprend à charger un modèle. C'est aussi un prétexte pour découvrir la programmation avec Python et Jupyter pour les SHS.\n",
    "\n",
    "3. Dans une utilisation (très) avancée, cela permet aussi de \"fine-tuner\" les modèles de Whisper afin qu'ils soient mieux adapter à ses propres corpus.\n",
    "\n",
    "### les inconvénients\n",
    "\n",
    "1. Pas toujours simple d'installer Whisper et les librairies nécessaires pour la retranscription (incompatibilité des versions, etc.). Ce n'est pas une solution \"clé en main\"\n",
    "\n",
    "2. L'utilisation de Whisper demande beaucoup de ressources. Selon la performance de votre matériel informatique, la retranscription prendra plus ou moins de temps et vous ne pourrez pas nécessairement utiliser les modèles les plus \"gros\".\n",
    "\n",
    "\n",
    "Pour éviter au maximum ces problèmes, nous utilisons le SSP Cloud de l'INSEE qui permet d'avoir le même espace de travail. \n",
    "Une autre solution, celle qu'on verra ensuite, est de faire appel aux services d'Huma-num lorsqu'on a des fichiers volumineux, de nombreux entretiens ou que l'on souhaite utiliser les modèles les plus performants.\n",
    "\n",
    "### Installation des librairies Python\n",
    "\n",
    "L'ensemble des librairies sont déjà installées. Toutefois si vous avez besoin de les réinstaller, il suffit de \"décommenter\" la ligne de code ci-dessous (i.e. enlever le '#') et de l'éxecuter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc790509-c585-46c5-9923-b4e4b80d712e",
   "metadata": {},
   "source": [
    "#### Librairie pour manipuler des fichiers audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee68aaa-45f5-422c-a00b-45e8ff824d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydub audioop-lts ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub\n",
    "from IPython.display import Audio, display #pour écouter les extraits audio avec un notebook jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8018f0-fe7c-4c5a-8acd-12c8eedc6060",
   "metadata": {},
   "source": [
    "#### Installation du module Whisper et chargement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc0942-a548-4c4d-b398-b9d014f447bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import time\n",
    "import csv\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a030ef-b5b2-4167-822a-de53db0138fd",
   "metadata": {},
   "source": [
    "Afin de connaître les modèles disponibles, on peut exécuter la commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c48a3-4720-498c-a2a4-8ea97801b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper.available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0320d-0f36-423c-9553-5f4290ba6287",
   "metadata": {},
   "source": [
    "Les modèles terminant par \".en\" sont ceux qui ont été entrainés uniquement sur des corpus anglophone. Les autres ont été entrainés sur des coprus multilingues.\n",
    "Dans cet atelier, nous allons testés les quatre modèle suivants : \"tiny\", \"medium\", \"large\" et \"large-v3\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c90cb-4632-4001-80f0-63d0d84a4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_model = whisper.load_model(\"tiny\")\n",
    "medium_model = whisper.load_model(\"medium\")\n",
    "large_model = whisper.load_model(\"large\")\n",
    "largev3_model = whisper.load_model(\"large-v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30ec93",
   "metadata": {},
   "source": [
    "On peut déjà constater que la taille des modèles augmentent ainsi que le temps de chargement\n",
    "\n",
    "### Charger et segmenter un mp3\n",
    "\n",
    "On commence par charger l'entretien (au format mp3). On créer pour cela un dossier \"records/\" dans lequel on télécharge notre fichier mp3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "itw = pydub.AudioSegment.from_mp3(\"../records/grazia_borrini_07-06-18_part-1.MP3\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10d687-b24f-4f3a-a5df-2ec984eded7f",
   "metadata": {},
   "source": [
    "La ligne ci-dessous permet d'extraire un morceau d'entretien d'une minute entre la 10e et la 11e minute. La briéveté de l'extrait permettra de faire des tests avec plusieurs modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f83f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract = itw[600*1000:660*1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3bb60",
   "metadata": {},
   "source": [
    "On enregistre notre extrait en exécutant la ligne ci-dessous. On remarque qu'un nouveau fichier sample.mp3 est apparu dans le dossier \"records/\".\n",
    "![](../figures/Capture_ecran_2025-12-08_15-33-24_sample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f92e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub.AudioSegment.export(extract,\"../records/sample.mp3\") #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949faac6-8644-47f9-8f84-dfc36d8eca67",
   "metadata": {},
   "source": [
    "### Pour écouter l'extrait audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8f929-eb15-49f1-a0ca-f0ecb59e5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio('../records/sample.mp3', autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084f832",
   "metadata": {},
   "source": [
    "## Retranscrire l'extrait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2839c",
   "metadata": {},
   "source": [
    "Nous allons maintenant tester la retranscription sur notre extrait en utilisant différents modèles. L'objectif est de comparer les résultats et définir le \"meilleur\" modèle en foction de la qualité de la transcription et du temps.\n",
    "Le résultat est retourné sous la forme d'une structure json.\n",
    "\n",
    "À noter qu'on utilise deux boucles `for` dans la cellule ci-après. La première permet de répéter l'opération de retranscription pour chaque modèle testé. La seconde d'afficher le résultat de la retranscription.\n",
    "\n",
    "Les boucles `for` en Python sont essentielles pour itérer sur des séquences et effectuer des opérations répétitives de manière efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2dc824-177d-450f-bf9e-92c765a69f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for n, model in enumerate([tiny_model, medium_model, large_model, largev3_model]):\n",
    "    start = time.time() # on lance le chronomètre\n",
    "    retranscribe = model.transcribe(\"../records/sample.mp3\", verbose=None, fp16=False)\n",
    "    print(f\"Temps écoulé : \", time.ctime(time.time() - start)[11:19])\n",
    "    if n == 1:\n",
    "        result_medium = retranscribe\n",
    "    for n, x in enumerate(retranscribe[\"segments\"]):\n",
    "        print(f\"Segment {n} : {x[\"text\"]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf0851f-eebe-4c93-9b7e-96375cb57f77",
   "metadata": {},
   "source": [
    "Dans la cellule ci-dessus, on utilise une boucle `for` pour afficher le résultat de la retranscription pour chacun des modèles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c89ff-1013-4ad4-976c-a5743e7661c6",
   "metadata": {},
   "source": [
    "On constate que les résultats produits par le modèle \"Tiny\" sont très mauvais. Ils sont nettement meilleurs avec le modèle médium.\n",
    "\n",
    "On constate également que la différence de résultats entre les modèles médium et large n'est pas flagrante. Si on prend en compte la durée de la retranscription, on peut s'interroger sur l'intérêt d'utiliser le modèle large. \n",
    "\n",
    "Enfin, dans tous les cas, les modèles produisent des erreurs. Le plus souvent, ce sont des erreurs de transcription : le texte ne correspond pas à ce qui est dit. Il arrive aussi que Whisper omette de retranscrire un passage. L'utilisation de Whisper ne dispense donc pas d'écouter les entretiens. Ainsi on va faciliter le travail de retranscription sans totalement perdre le lien avec le matériaux brut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566a47a",
   "metadata": {},
   "source": [
    "## Mise en forme et sauvegarde\n",
    "\n",
    "(inspiration Yacine Chitour)\n",
    "\n",
    "La sortie obtenue après la retranscription prend la forme d'un dictionnaire. On va donc \"mettre en forme\" cette sortie pour qu'on puisse sauvegarder le résultat dans des formats plus facile à manipuler avec des logiciels de traitements de texte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a0323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "speech = pd.DataFrame.from_dict(result_medium['segments'])\n",
    "speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertir(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d},{ms}\"\n",
    "\n",
    "def convert_to_second(str_time):\n",
    "    h = int(str_time.split(\":\")[0])*3600\n",
    "    m = int(str_time.split(\":\")[1])*60\n",
    "    s= int(str_time.split(\":\")[2].split(\",\")[0])\n",
    "    ms = float(\"0.\"+str_time.split(',')[-1])\n",
    "    return h+m+s+ms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb7bfc1-4bcf-455b-86f7-d8cce32a90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = convertir(10.64)\n",
    "print(h, convert_to_second(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865863c-0959-4836-a009-86f6bf6e76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_transcript(transcription, file_name=\"\", extention=[]):\n",
    "    print(len(extention))\n",
    "    if len(extention) == 0:\n",
    "        guess_from_name_file = file_name.split(\".\")[-1]\n",
    "        print(guess_from_name_file)\n",
    "        try:\n",
    "            if guess_from_name_file in [\"txt\", \"csv\", \"srt\"]:\n",
    "                    extention.append(guess_from_name_file)\n",
    "        except:\n",
    "            print(\"Veuillez préciser l'extension de sotie en choisissant parmi les trois formats suivants : '.txt', '.csv', '.srt'!\\n\")\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    for n, x in enumerate(extention):\n",
    "        file_name_without_extention = file_name.split(\".\")[0]\n",
    "        if x == \"txt\":\n",
    "            file_name_with_ext = f\"../records/{file_name_without_extention}.{x}\"\n",
    "            with open(file_name_with_ext, 'w', encoding='utf-8') as f:\n",
    "                for segment in transcription[\"segments\"]:\n",
    "                    start_time = convertir(segment['start'])\n",
    "                    end_time = convertir(segment['end'])\n",
    "                    f.write(f\"{start_time} - {end_time}: {segment['text']}\\n\")\n",
    "        elif x == \"srt\":\n",
    "            file_name_with_ext = f\"../records/{file_name_without_extention}.{x}\"\n",
    "            with open(file_name_with_ext, 'w', encoding='utf-8') as f:\n",
    "                for segment in transcription[\"segments\"]:\n",
    "                    start_time = convertir(segment['start'])\n",
    "                    end_time = convertir(segment['end'])\n",
    "                    f.write(f\"{start_time} --> {end_time}\\n{segment['text'].strip()}\\n\\n\")\n",
    "        elif x == \"csv\":\n",
    "            file_name_with_ext = f\"../records/{file_name_without_extention}.{x}\"\n",
    "            with open(file_name_with_ext , 'w', newline='') as csvfile:\n",
    "                fieldnames = ['id','start', 'end','text','start_in_ms','end_in_ms']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                for segment in transcription[\"segments\"]:\n",
    "                    start_time = convertir(segment['start'])\n",
    "                    end_time = convertir(segment['end'])\n",
    "                    writer.writerow({'id':'seg_'+str(segment['id']), \n",
    "                                     'start': start_time,\n",
    "                                     'end': end_time,\n",
    "                                     'text':segment['text'].strip(),\n",
    "                                     'start_in_ms':segment['start'],\n",
    "                                     'end_in_ms':segment['end']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff7566-fd17-4b7a-b213-ea979c4d30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"2026-01-09_itw_borrini.tsv\"\n",
    "\n",
    "save_transcript(result_medium, file_name= file_name, extention=[\"csv\", \"txt\", \"srt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43695caa-43c5-4e88-a555-bedd11dd4ddf",
   "metadata": {},
   "source": [
    "**Fin de la partie \"Whisper en local\"**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
